{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]\n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_json('../data/train.json/train.json')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6 16  4  7  7 10 17  9 13  9  9  3  9 13  9  7  1  9 18 19 18 13 16  3  9\n",
      "  3  2  9  3 13  9  2 13 18  9  2  9  4 16 16  9  0 13  7 13  3  5 16 16 16\n",
      " 11 16  9 16  9 10 11  7  9  8 18 18  7 10  9 18 12  5  5 16 17  7 14  9  9\n",
      " 14 14 19 11 13  2 16  5  7  7  9  9  7 12 17  9 16 16  6 13 13 16  7  9  9]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(max_features = 2000)\n",
    "ingredients = train['ingredients']\n",
    "words_list = [' '.join(x) for x in ingredients]\n",
    "\n",
    "#Make label encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train[\"cuisine\"])\n",
    "\n",
    "print le.transform(train[\"cuisine\"])[0:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39774, 2000)\n",
      "(39774, 3010)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2507: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#create a bag of words and convert to a array and then print the shape\n",
    "bag_of_words = vectorizer.fit(words_list)\n",
    "bag_of_words = vectorizer.transform(words_list).toarray()\n",
    "print(bag_of_words.shape)\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "tfidf = vectorizer.fit_transform(words_list).toarray()\n",
    "print tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00035198873636\n"
     ]
    }
   ],
   "source": [
    "#Initilize a random forest classifier with 500 trees and fit it with the bag of words we created \n",
    "forest = RandomForestClassifier(n_estimators = 500) \n",
    "forest = forest.fit( bag_of_words, train[\"cuisine\"])\n",
    "\n",
    "incorrect = 0\n",
    "for i in xrange(bag_of_words.shape[0]):\n",
    "    p = forest.predict(bag_of_words[i,:])\n",
    "    a = train[\"cuisine\"][i]\n",
    "    if(not(a==p[0])):\n",
    "        incorrect += 1\n",
    "        \n",
    "print float(incorrect)/bag_of_words.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now read the test json file in \n",
    "test = pd.read_json('../data/test.json/test.json')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Do the same thing we did with the training set and create a array using the count vectorizer. \n",
    "test_ingredients = test['ingredients']\n",
    "test_ingredients_words = [' '.join(x) for x in test_ingredients]\n",
    "test_ingredients_array = vectorizer.transform(test_ingredients_words).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the random forest to make cusine predictions\n",
    "result = forest.predict(test_ingredients_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print type(result)\n",
    "print result.shape\n",
    "print result[0]\n",
    "\n",
    "for i in xrange(len(result)):\n",
    "    print result[i], test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy the results to a pandas dataframe with an \"id\" column and\n",
    "# a \"cusine\" column\n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"cuisine\":result} )\n",
    "\n",
    "# Use pandas to write the comma-separated output file\n",
    "output.to_csv( \"Bag_of_Words_model.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
